<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml" lang="ru">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Парсинг удаленного источника (сайта) &mdash; Документация mydoc 1</title>
    
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/translations.js"></script>
    <link rel="top" title="Документация mydoc 1" href="../index.html" />
    <link rel="prev" title="Парсинг базы вакансий" href="primer_big_local_file.html" />
   
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="id1">
<h1>Парсинг удаленного источника (сайта)<a class="headerlink" href="#id1" title="Ссылка на этот заголовок">¶</a></h1>
<p>Здесь мы рассмотрим пример парсинга интернет-сайта. Одним из наиболее популярных объектов парсинга являются сайты относящиеся к одному из типов</p>
<ul class="simple">
<li>интернет-магазины</li>
<li>сайты объявлений купли-продажи</li>
<li>сайты риэлтерских агентств</li>
</ul>
<p>Все они хранят большой объем данных соответствующей предметной области. А задача парсинга - извлечь эти данные и сохранить в удобном для последующего поиска и анализа виде. Адреса некоторых таких сайтов можно узнать здесь ___</p>
<p>Поскольку в предыдущем примере мы извлекали данные из общероссийской базы вакансий, продолжим данную тематику и рассмотрим пример извлечения данных из сайта популярного рекрутинкового агенства HeadHunter ___</p>
<p>Перед разбором примера следует заметить, что на рассматриваемом сайте информацию о вакансиях можно извлекать минимум тремя способами</p>
<ol class="arabic simple">
<li>используя API сайта</li>
<li>используя rss сайта</li>
<li>непосредственно со страниц сайта</li>
</ol>
<p>Однако, не все сайты предоставляют такое разноообразие способов для извлечения данных. Поэтому, в данном примере мы рассмотрим наиболее универсальный (хотя, зачастую, и не самый удобный) способ под номером 3 - извлечение данных непосредственно со страниц сайта</p>
<p>Следует понимать, что процесс извлечения данных может быть реализован несколькими путями. Чтобы выбрать наиболее эффективный путь (с точки зрения времени и трудозатрат) первым и самым важным этапом является анализ структуры сайта и страниц, хранящих необходимую информацию.</p>
<div class="section" id="id2">
<h2>Этап 1. Анализ сайта<a class="headerlink" href="#id2" title="Ссылка на этот заголовок">¶</a></h2>
<p>Анализ - творческий процесс, во многом зависит структурой сайта и определяет последующий способ его парсинга. В данном разделе даются рекомендации по __ какой путь выберите Вы зависит во многом от вашего опыта</p>
<div class="section" id="id3">
<h3>Сбор информации о ссылка сайта, хранящих необходимые данные<a class="headerlink" href="#id3" title="Ссылка на этот заголовок">¶</a></h3>
<p>Сбор информации может выполняться одним из двух способов</p>
<p>Автоматический способ - самый простой но более длительный и подходит не для всех типов сайтов. Суть его заключается в том, чтобы дать парсеру указание обойти все доступные страницы сайта, извлечь из них все внутренние ссылки сайта и сохранить их в отдельный файл. Делается это следующей командой</p>
<p id="id4">Затем нужно просмотреть файл со собранными ссылками и выделить те из них, по которым хранятся необходимые данные. Например</p>
<p id="id5">Из листинга видно, что достаточно много ссылок имеют такую структуру ___</p>
<p>Перейдя по любой из них в браузере мы попадаем на страницу, содержащую нужные нам данные. Значит, именно эти страницы и нужно указать функции парсера для извлечения данных. Делается это примерно так</p>
<p>Способ второй - ручной. Переходя в браузере по ссылкам сайта вручную определить ссылки какого типа нам необходимы. Например ___</p>
<p>Очевидно, что бля данного способа нам нет нужны собирать все ссылки с сайта - мы можем выполнять парсинг генерируя их &#8220;на лету&#8221;. Примерно так</p>
<hr class="docutils" />
<p>Первая особенность интернет сайтов как источника xml данных заключается в том, что данные хранятся по адресам (страниц) небольшими порциями. И таких адресов у сайта очень много. А кроме того, сайт включает адреса к другим данным, нас не интересующим. В нашем примере это адреса на описание компаний, разместивших вакансии, адреса на страницы ___ и т.д. Нас интересуют только адреса с описанием вакансий.</p>
<p>Поэтому, задача данного этапа - собрать все адреса сайта и оставить только те, по которым хранятся интересующие нас данные и.</p>
<p>Решается эта задача с помощью следующего кода</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">url</span><span class="o">=</span><span class="s1">&#39;http://www.hh.ru&#39;</span>
<span class="n">x</span><span class="o">=</span><span class="n">xmlParser</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="s1">&#39;html&#39;</span><span class="p">)</span>
<span class="n">x</span><span class="o">.</span><span class="n">header</span><span class="o">=</span><span class="p">{}</span>
<span class="n">x</span><span class="o">.</span><span class="n">html</span><span class="o">.</span><span class="n">getAllLinks</span><span class="p">(</span><span class="n">link_file</span><span class="o">=</span><span class="s1">&#39;hh.lst&#39;</span><span class="p">,</span> <span class="n">maxdeep</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Код сканирует сайт и сохраняет все адреса в файл hh.lst</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">maxdeep:</th><td class="field-body">важный параметр метода - определяет глубину поиска ссылок. Т.е. сначала из первой (основной) страницы сайта извлекаются все ссылки на другие страницы. Затем метод переходит по каждой этой ссылке и уже из этой страницы извлекает все ссылкию Затем переходит по ним и опять извлекает все ссылки. Т.е. проходит вглубь сайта до уровня <strong>maxdeep</strong>. Значение -1 означает что ссылки будут извлекаться со всех доступных страниц сайта.</td>
</tr>
</tbody>
</table>
<p>Задача данного метода - собрать достаточное количество ссылок, чтобы понять структуру сайта. Поэтому иногда не обязательно собирать все ссылки, а ограничиться глубиной 5-10</p>
</div>
</div>
<div class="section" id="id7">
<h2>Этап 2. Анализ ссылок<a class="headerlink" href="#id7" title="Ссылка на этот заголовок">¶</a></h2>
<p>Теперь необходимо вручную провести небольшой анализ ссылок. Дело в том, что нужные нам одни и те же данные могут быть представлены на сайте в разных формах и по разным ссылкам (путям). Для нашего примера это выглядит так.
Мы собираем данные о вакансиях, размещенных на сайте. Вакансии представлены в следующих форматах</p>
<ol class="arabic simple">
<li>Самая подробная информация информация о вакансии хранится на страницах сайта примерно такого формата <a class="reference external" href="https://hh.ru/vacancy/16718241">https://hh.ru/vacancy/16718241</a>. По таким ссылкам на каждой странице хранятся данные только по одной вакансии</li>
<li>Список вакансий хранится по ссылкам такого типа <a class="reference external" href="https://hh.ru/search/vacancy?page=3">https://hh.ru/search/vacancy?page=3</a>. Здесь на каждой странице хранится сокращенная информация по 20 вакансиям. Но есть ограничение - максимально допустимое значение параметра -99. Т.о. меняя только этот параметр можно получить данные о 2000 вакансиях. Чтобы получить больше данных - на помощь приходят отфильтрованные списки.</li>
<li>Отфильтронаннык списки вакансий хранятся по тому же адресу что и в 2 <a class="reference external" href="https://hh.ru/search/vacancy?page=3">https://hh.ru/search/vacancy?page=3</a>, но с добавлением к адресу дополнительных фильтров, например <a class="reference external" href="https://hh.ru/search/vacancy?page=3&amp;area=1">https://hh.ru/search/vacancy?page=3&amp;area=1</a> - вакансии по г. Москва. Просматривая ссылки - легко выделить следуюште параметры фильтров</li>
</ol>
<p><em>areaId</em> - номер региона в котором размещена вакансия (__ уникальных значений)</p>
<p><em>only_with_salary=true</em> - вакансии только с указанной зарплатой</p>
<p><em>salary</em> - нижняя граница заработной платы</p>
<p><em>experience=between1And3</em> - опыт работы</p>
<p><em>specialization=21</em> - профессиональная область и специализации</p>
<p><em>industry=5</em> - отрасль кампании</p>
<p><em>label=not_from_agency</em> - исключить вакансии агенств</p>
<p><em>employment</em> - тип занятости</p>
<p><em>schedule</em> - график работы</p>
<p>Каждый параметр имеет ограниченное количество допустимых значений. Узнать их можно из списка ссылок. для этого вызовем метод</p>
<ol class="arabic simple" start="4">
<li>Список вакансий по профессиям хранятся по адресу <a class="reference external" href="https://hh.ru/catalog/Avtomobilnyj-biznes/Nachalnii-uroven/page-2">https://hh.ru/catalog/Avtomobilnyj-biznes/Nachalnii-uroven/page-2</a></li>
<li>Список краткого описания вакансий по кампаниям хранится по адресу <a class="reference external" href="https://hh.ru/employer/5406">https://hh.ru/employer/5406</a></li>
</ol>
<p>Такое разнообразие представления информации ___</p>
<ul class="simple">
<li>Если мы хотим собрать наиболее полную базу вакансий для ___</li>
<li>если мы хотим проанализировать рынок вакансий в сравнении с общероссийской базой - лучше всего использовать 3-й тип ссылок</li>
<li>если мы хотим регулярно отслеживать поступления новых вакансий по перечню определенных профессий или по определенным кампаниям, например, чтобы при появлении таких вакансий автоматически отправлять отчет на электронную почту, соотвественно используем 4 или 5 тип ссылок</li>
</ul>
<p>Далее в данном примере мы будем рассматривать задачу сравнения вакансий hh с общероссийской базой</p>
</div>
<div class="section" id="id8">
<h2>Этап 3. Извлечение данных по нужным ссылкам<a class="headerlink" href="#id8" title="Ссылка на этот заголовок">¶</a></h2>
<p>На данном этапе существует два подхода к извлечению данных. Точнее - к получению ссылок на страницы из которых парсер будет извлекать данные</p>
<ol class="arabic simple">
<li>Указать шаблон для ссылок по которым хранятся необходимые нам данные</li>
<li>Генерировать необходимые ссылки.</li>
</ol>
<p>Рассмотрим подробно оба этих способа. Ни один из них не является преимущественным, применение того или иного способа зависит организации сайта, от времени, которым Вы располагается для извлечения данных и навыков программирования.</p>
<div class="section" id="id9">
<h3>Способ 1. Определение шаблона ссылок<a class="headerlink" href="#id9" title="Ссылка на этот заголовок">¶</a></h3>
<p>не работает</p>
</div>
<div class="section" id="id10">
<h3>Способ 2. Генерация ссылок<a class="headerlink" href="#id10" title="Ссылка на этот заголовок">¶</a></h3>
<p>Данный способ позволяет вообще пропустить этап 2 (сбор ссылок сайта) но при этом
основан на предварительном ручном изучении существующих фильтров и их допустимых значений (см пункт 3 этапа 2). После этого в коре парсинга необходимо сформировать словарь фильтров и их допустимых значений, после чего можно запустить парсер для извлечения данных по генерируемым ссылкам. код будет примерно такой</p>
<p id="id11">___ проверить оба способа и сравнить их точность ___</p>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Оглавление</a></h3>
  <ul>
<li><a class="reference internal" href="#">Парсинг удаленного источника (сайта)</a><ul>
<li><a class="reference internal" href="#id2">Этап 1. Анализ сайта</a><ul>
<li><a class="reference internal" href="#id3">Сбор информации о ссылка сайта, хранящих необходимые данные</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id7">Этап 2. Анализ ссылок</a></li>
<li><a class="reference internal" href="#id8">Этап 3. Извлечение данных по нужным ссылкам</a><ul>
<li><a class="reference internal" href="#id9">Способ 1. Определение шаблона ссылок</a></li>
<li><a class="reference internal" href="#id10">Способ 2. Генерация ссылок</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="primer_big_local_file.html" title="предыдущая глава">Парсинг базы вакансий</a></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>Эта страница</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/article/primer_remote_source.txt"
            rel="nofollow">Исходный текст</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Быстрый поиск</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Искать" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2016, zlukfo.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.7</a>
      
      |
      <a href="../_sources/article/primer_remote_source.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>